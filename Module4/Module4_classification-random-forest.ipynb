{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlMGrZNCBNKP"
   },
   "source": [
    "# Classifying Malicious Software using Random Forest\n",
    "\n",
    "The emergence of graph data across many scientific fields has led to intense interest in the development of representation learning techniques that encode structured information into low dimensional space for a variety of important downstream tasks (e.g., toxic molecule detection, community clustering, malware detection).\n",
    "\n",
    "In this lab, we walk through how to use **random forests** to classify different *types* of malicious software using function call graphs (FCGs) extracted from malicious files. Each FCG represents the calling relationships between functions in a program, where nodes are functions and edges indicate inter-procedural calls. We obtain these FCGs from [**MalNet**](https://mal-net.org/), a large-scale graph classification database.Specifically, we will look at how to:\n",
    "\n",
    "- Part 1: Download and process the data,\n",
    "- Part 2: Get train and test data\n",
    "- Part 3: Random Forest Classifier Hyperparameter tuning\n",
    "- Part 4: Measuring Accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NN5U913TEPCn"
   },
   "source": [
    "## Part 1. Downloading and processing the data\n",
    "\n",
    "We first download the graph data from the MalNet website, [here](http://malnet.cc.gatech.edu/graph-data/malnet-graphs-tiny.tar.gz) and [here](http://malnet.cc.gatech.edu/split-info/split_info_tiny.zip), and store it locally in the folder `notebooks/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BKC_9M5EkMe"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import requests\n",
    "\n",
    "def download_data(url, target_path):\n",
    "    \"\"\"\n",
    "    Download MalNet-Tiny data to the local device\n",
    "    :param: url: a string representing the url download location\n",
    "    :param: target_path: a string representing the local storage location\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # check that the data was successfully retrieved\n",
    "    if response.status_code == 200:\n",
    "        with open(target_path, 'wb') as f:\n",
    "            f.write(response.raw.read())\n",
    "\n",
    "    # uncompress the downloads\n",
    "    shutil.unpack_archive(target_path, 'notebooks/')\n",
    "\n",
    "download_data(url='http://malnet.cc.gatech.edu/graph-data/malnet-graphs-tiny.tar.gz', target_path='notebooks/malnet-graphs-tiny.tar.gz')\n",
    "download_data(url='http://malnet.cc.gatech.edu/split-info/split_info_tiny.zip', target_path='notebooks/split_info_tiny.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cEsYYk0FRRE"
   },
   "source": [
    "Now that the data has been downloaded, lets gather the file paths and label information for the train, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nWMk9MvZE7Yy",
    "outputId": "66bd238d-d570-48cb-bde2-cf57ffdc9943",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_split_info(data_type, data_dir='notebooks/malnet-graphs-tiny/'):\n",
    "    \"\"\"\n",
    "    Get the file paths and labels for the train, val or test data\n",
    "    :param: data_type: a string representing the data selection 'train', 'val' or 'test'\n",
    "    :param: the graph directory\n",
    "    :return: list of graph filepaths, list of labels, and label dictionary \n",
    "    \"\"\"\n",
    "\n",
    "    # read the train/val/test file split info into memory\n",
    "    with open('notebooks/split_info_tiny/type/{}.txt'.format(data_type), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # parse graph file paths\n",
    "    files = [data_dir + l.strip() + '.edgelist' for l in lines]\n",
    "    print('Number of {} samples: {}'.format(data_type, len(files)))\n",
    "\n",
    "    # get the class labels for each graph\n",
    "    graph_classes = sorted(list(set([file.split(data_dir)[1].split('/')[0] for file in files])))\n",
    "    label_dict = {t: idx for idx, t in enumerate(graph_classes)}\n",
    "    labels = [label_dict[file.split(data_dir)[1].split('/')[0]] for file in files]\n",
    "\n",
    "    return files, labels, label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__<span style=\"color:red\">Exercise1a:</span>__: Call get_split_info function with parameter data_type='train'. Save output into 3 variables: files_train, train_labels, label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__<span style=\"color:red\">Exercise1b:</span>__: Call get_split_info function with parameter data_type='val'. Save output into 2 variables: files_val, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__<span style=\"color:red\">Exercise1c:</span>__: Call get_split_info function with parameter data_type='test'. Save output into 2 variables: files_test, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZLAwdrK8gnD"
   },
   "source": [
    "To get a feeling for the data we are going to be working with, lets visualize one of the graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "id": "Ol4-xzMn8hB_",
    "outputId": "44f8f513-95fe-4dab-b449-0aa7c4553bf5"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load a single function call graph\n",
    "graph = nx.read_edgelist(files_train[2], create_using=nx.DiGraph)\n",
    "\n",
    "# plot the graph using the Kamada Kawai graph layout\n",
    "plt.figure(num=None, figsize=(15, 15))\n",
    "plt.axis('off')\n",
    "nx.draw_kamada_kawai(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEj2Xwoz_15D"
   },
   "source": [
    "In the figure above, we can see that the graph is directed which represents the interprocedural function calls i.e., each node is a function and an edge represents that function calling another function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sM3rPjTkWpQs"
   },
   "source": [
    "## Part 2. Get train and test data\n",
    "\n",
    "Let's now break our data into a training set, a validation set, and a testing set. We will train our random forest models with our training data and then tune the model's hyperparameters using the validation data. We will finally evaluate the best random forest model using our testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FArci1UWpQs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "train_arr, val_arr, test_arr = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aAdPK3CAWpQt"
   },
   "outputs": [],
   "source": [
    "for file in files_train:\n",
    "  graph = nx.read_edgelist(file)\n",
    "  train_arr.append([len(graph.nodes), len(graph.edges)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPrffi8hWpQt"
   },
   "outputs": [],
   "source": [
    "for file in files_val:\n",
    "  graph = nx.read_edgelist(file)\n",
    "  val_arr.append([len(graph.nodes), len(graph.edges)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4T4xrjGWpQt"
   },
   "outputs": [],
   "source": [
    "for file in files_test:\n",
    "  graph = nx.read_edgelist(file)\n",
    "  test_arr.append([len(graph.nodes), len(graph.edges)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Random Forest Classifier (sklearn) Hyperparamter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are all the different hyperparameter arguments we want to vary and the respective inputs that we want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_choice = [25, 50, 100, 200]\n",
    "max_depth_choice = [4, 16, 32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test all the different combinations of hyperparameters and return the set of hyperparameters that fit the validation dataset the best. If there are multiple combinations that achieve the same accuracy, use the combination that leads to the simplest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "                 'n_estimators': [25, 50, 100, 200],\n",
    "                 'max_depth': [4, 16, 32],\n",
    "             }\n",
    "\n",
    "\n",
    "rf_cv_model = GridSearchCV(rf_model, param_grid, cv=10).fit(val_arr, val_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_tuned = RandomForestClassifier(**rf_cv_model.best_params_).fit(train_arr, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_tuned.predict(test_arr)\n",
    "print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Random Forest Classifier (cuML) dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IprKH8AWpQu"
   },
   "source": [
    "Now we will need to convert it into values that cuML's random forest classifier (RFC) takes. The documentation for cuML's RFC can be found [here](https://docs.rapids.ai/api/cuml/stable/api.html#cuml.ensemble.RandomForestClassifier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__<span style=\"color:red\">Exercise2a:</span>__: Create numpy array for the datasets and convert to 32-bit floating-point number(float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__<span style=\"color:red\">Exercise2b:</span>__: Create numpy array for the datasets labels and convert to 32-bit int number(int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xJPNsQ1cWpQu",
    "outputId": "9bb4bf53-f4e2-4424-ea8a-7aa9dace8e46"
   },
   "outputs": [],
   "source": [
    "#Looking at the shape of all the arrays\n",
    "print(\"train_arr: \", train_arr.shape)\n",
    "print(\"val_arr: \", val_arr.shape)\n",
    "print(\"test_arr: \", test_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rlss3kKiWpQu",
    "outputId": "83bee7e7-7c68-4d08-bdcf-e8b9d77b975a"
   },
   "outputs": [],
   "source": [
    "print(\"train_arr dict: \", label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdNLe_9BWpQv"
   },
   "source": [
    "## Part 5. Random Forest Classifier (cuML) Hyperparamter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_XTplVXWpQv"
   },
   "outputs": [],
   "source": [
    "from cuml.ensemble import RandomForestClassifier as cuRFC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bvYUCJCWpQw"
   },
   "source": [
    "__<span style=\"color:red\">Exercise3a:</span>__: Rewrite the Random Forest Classifier (sklearn) Hyperparamter tuning code into cuML version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__<span style=\"color:red\">Exercise3b:</span>__: Calculate the time taken for cuRFC to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__<span style=\"color:red\">Exercise3c:</span>__: Show the best parameters for cuRFC trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Module-14-Lab-classification-random-forest.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
