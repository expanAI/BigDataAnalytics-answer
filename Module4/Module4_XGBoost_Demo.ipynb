{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to XGBoost with RAPIDS\n",
    "#### By Paul Hendricks\n",
    "-------\n",
    "\n",
    "While the world’s data doubles each year, CPU computing has hit a brick wall with the end of Moore’s law. For the same reasons, scientific computing and deep learning has turned to NVIDIA GPU acceleration, data analytics and machine learning where GPU acceleration is ideal. \n",
    "\n",
    "NVIDIA created RAPIDS – an open-source data analytics and machine learning acceleration platform that leverages GPUs to accelerate computations. RAPIDS is based on Python, has pandas-like and Scikit-Learn-like interfaces, is built on Apache Arrow in-memory data format, and can scale from 1 to multi-GPU to multi-nodes. RAPIDS integrates easily into the world’s most popular data science Python-based workflows. RAPIDS accelerates data science end-to-end – from data prep, to machine learning, to deep learning. And through Arrow, Spark users can easily move data into the RAPIDS platform for acceleration.\n",
    "\n",
    "In this notebook, we'll show the acceleration one can gain by using GPUs with XGBoost in RAPIDS.\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "* Setup\n",
    "* Load Libraries\n",
    "* Load/Simulate Data\n",
    "  * Load Data\n",
    "  * Simulate Data\n",
    "  * Split Data\n",
    "  * Check Dimensions\n",
    "* Convert NumPy data to DMatrix format\n",
    "* Set Parameters\n",
    "* Train Model\n",
    "* Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This notebook was tested using the `nvcr.io/nvidia/rapidsai/rapidsai:0.5-cuda10.0-runtime-ubuntu18.04-gcc7-py3.7` Docker container from [NVIDIA GPU Cloud](https://ngc.nvidia.com) and run on the NVIDIA Tesla V100 GPU. Please be aware that your system may be different and you may need to modify the code or install packages to run the below examples. \n",
    "\n",
    "If you think you have found a bug or an error, please file an issue here: https://github.com/rapidsai/notebooks/issues\n",
    "\n",
    "To start, let's see what hardware we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:03:38.237293Z",
     "start_time": "2018-11-06T21:03:37.388285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 13 09:42:07 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000001:00:00.0 Off |                  Off |\r\n",
      "| N/A   28C    P0    25W / 250W |      0MiB / 16384MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's see what CUDA version we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:03:39.490984Z",
     "start_time": "2018-11-06T21:03:39.134608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\r\n",
      "Built on Wed_Oct_23_19:24:38_PDT_2019\r\n",
      "Cuda compilation tools, release 10.2, V10.2.89\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries\n",
    "\n",
    "Let's load some of the libraries within the RAPIDs ecosystem and see which versions we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:03:41.067879Z",
     "start_time": "2018-11-06T21:03:40.256654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy Version: 1.19.4\n",
      "pandas Version: 0.25.3\n",
      "XGBoost Version: 1.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np; print('numpy Version:', np.__version__)\n",
    "import pandas as pd; print('pandas Version:', pd.__version__)\n",
    "import xgboost as xgb; print('XGBoost Version:', xgb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/Simulate data\n",
    "\n",
    "### Load Data\n",
    "\n",
    "We can load the data using `pandas.read_csv`.\n",
    "\n",
    "### Simulate Data\n",
    "\n",
    "Alternatively, we can simulate data for our train and validation datasets. The features will be tabular with `n_rows` and `n_columns` in the training dataset, where each value is either of type `np.float32` if the data is numerical or `np.uint8` if the data is categorical. Both numerical and categorical data can also be combined; for this experiment, we have ignored this combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for simulating data\n",
    "def simulate_data(m, n, k=2, numerical=False):\n",
    "    if numerical:\n",
    "        features = np.random.rand(m, n)\n",
    "    else:\n",
    "        features = np.random.randint(2, size=(m, n))\n",
    "    labels = np.random.randint(k, size=m)\n",
    "    return np.c_[labels, features].astype(np.float32)\n",
    "\n",
    "\n",
    "# helper function for loading data\n",
    "def load_data(filename, n_rows):\n",
    "    if n_rows >= 1e9:\n",
    "        df = pd.read_csv(filename)\n",
    "    else:\n",
    "        df = pd.read_csv(filename, nrows=n_rows)\n",
    "    return df.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "LOAD = False\n",
    "n_rows = int(1e5)\n",
    "n_columns = int(100)\n",
    "n_categories = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 101)\n",
      "CPU times: user 63.5 ms, sys: 52.3 ms, total: 116 ms\n",
      "Wall time: 115 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if LOAD:\n",
    "    dataset = load_data('/tmp', n_rows)\n",
    "else:\n",
    "    dataset = simulate_data(n_rows, n_columns, n_categories)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data\n",
    "\n",
    "We'll split our dataset into a 80% training dataset and a 20% validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify shape and indices\n",
    "n_rows, n_columns = dataset.shape\n",
    "train_size = 0.80\n",
    "train_index = int(n_rows * train_size)\n",
    "\n",
    "# split X, y\n",
    "X, y = dataset[:, 1:], dataset[:, 0]\n",
    "del dataset\n",
    "\n",
    "# split train data\n",
    "X_train, y_train = X[:train_index, :], y[:train_index]\n",
    "\n",
    "# split validation data\n",
    "X_validation, y_validation = X[train_index:, :], y[train_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Dimensions\n",
    "\n",
    "We can check the dimensions and proportions of our training and validation dataets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (80000, 100) float32 y_train:  (80000,) float32\n",
      "X_validation (20000, 100) float32 y_validation:  (20000,) float32\n",
      "X_train proportion: 0.8\n",
      "X_validation proportion: 0.2\n"
     ]
    }
   ],
   "source": [
    "# check dimensions\n",
    "print('X_train: ', X_train.shape, X_train.dtype, 'y_train: ', y_train.shape, y_train.dtype)\n",
    "print('X_validation', X_validation.shape, X_validation.dtype, 'y_validation: ', y_validation.shape, y_validation.dtype)\n",
    "\n",
    "# check the proportions\n",
    "total = X_train.shape[0] + X_validation.shape[0]\n",
    "print('X_train proportion:', X_train.shape[0] / total)\n",
    "print('X_validation proportion:', X_validation.shape[0] / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert NumPy data to DMatrix format\n",
    "\n",
    "With out data simulated and formatted as NumPy arrays, our next step is to convert this to a `DMatrix` object that XGBoost can work with. We can instantiate an object of the `xgboost.DMatrix` by passing in the feature matrix as the first argument followed by the label vector using the `label=` keyword argument. To learn more about XGBoost's support for data structures other than NumPy arrays, see the documentation for the Data Interface:\n",
    "\n",
    "\n",
    "https://xgboost.readthedocs.io/en/latest/python/python_intro.html#data-interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:03:55.278322Z",
     "start_time": "2018-11-06T21:03:54.059643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 130 ms, sys: 23.1 ms, total: 153 ms\n",
      "Wall time: 154 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/core.py:444: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"because it will generate extra copies and increase \" +\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalidation = xgb.DMatrix(X_validation, label=y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters\n",
    "\n",
    "There are a number of parameters that can be set before XGBoost can be run. \n",
    "\n",
    "* General parameters relate to which booster we are using to do boosting, commonly tree or linear model\n",
    "* Booster parameters depend on which booster you have chosen\n",
    "* Learning task parameters decide on the learning scenario. For example, regression tasks may use different parameters with ranking tasks.\n",
    "\n",
    "For more information on the configurable parameters within the XGBoost module, see the documentation here:\n",
    "\n",
    "\n",
    "https://xgboost.readthedocs.io/en/latest/parameter.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run XGBoost without GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'silent': 1, 'eval_metric': 'auc', 'objective': 'binary:logistic'}\n"
     ]
    }
   ],
   "source": [
    "# instantiate params\n",
    "params = {}\n",
    "\n",
    "# general params\n",
    "general_params = {'silent': 1}\n",
    "params.update(general_params)\n",
    "\n",
    "# booster params\n",
    "n_gpus = 0\n",
    "booster_params = {}\n",
    "\n",
    "if n_gpus != 0:\n",
    "    booster_params['tree_method'] = 'gpu_hist'\n",
    "    booster_params['n_gpus'] = n_gpus\n",
    "params.update(booster_params)\n",
    "\n",
    "# learning task params\n",
    "learning_task_params = {'eval_metric': 'auc', 'objective': 'binary:logistic'}\n",
    "params.update(learning_task_params)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "Now it's time to train our model! We can use the `xgb.train` function and pass in the parameters, training dataset, the number of boosting iterations, and the list of items to be evaluated during training. For more information on the parameters that can be passed into `xgb.train`, check out the documentation:\n",
    "\n",
    "\n",
    "https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training settings\n",
    "evallist = [(dvalidation, 'validation'), (dtrain, 'train')]\n",
    "num_round = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:04:50.201308Z",
     "start_time": "2018-11-06T21:04:00.363740Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:42:10] WARNING: /conda/conda-bld/xgboost_1591204529699/work/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation-auc:0.50718\ttrain-auc:0.54219\n",
      "[1]\tvalidation-auc:0.50541\ttrain-auc:0.55878\n",
      "[2]\tvalidation-auc:0.50782\ttrain-auc:0.56994\n",
      "[3]\tvalidation-auc:0.51270\ttrain-auc:0.58049\n",
      "[4]\tvalidation-auc:0.50758\ttrain-auc:0.58882\n",
      "[5]\tvalidation-auc:0.50772\ttrain-auc:0.59639\n",
      "[6]\tvalidation-auc:0.50897\ttrain-auc:0.60430\n",
      "[7]\tvalidation-auc:0.50962\ttrain-auc:0.61053\n",
      "[8]\tvalidation-auc:0.50935\ttrain-auc:0.61665\n",
      "[9]\tvalidation-auc:0.50636\ttrain-auc:0.62227\n",
      "[10]\tvalidation-auc:0.50519\ttrain-auc:0.62812\n",
      "[11]\tvalidation-auc:0.50463\ttrain-auc:0.63369\n",
      "[12]\tvalidation-auc:0.50427\ttrain-auc:0.63923\n",
      "[13]\tvalidation-auc:0.50484\ttrain-auc:0.64402\n",
      "[14]\tvalidation-auc:0.50718\ttrain-auc:0.64840\n",
      "[15]\tvalidation-auc:0.50809\ttrain-auc:0.65300\n",
      "[16]\tvalidation-auc:0.50677\ttrain-auc:0.65701\n",
      "[17]\tvalidation-auc:0.50706\ttrain-auc:0.66109\n",
      "[18]\tvalidation-auc:0.50516\ttrain-auc:0.66551\n",
      "[19]\tvalidation-auc:0.50649\ttrain-auc:0.66927\n",
      "[20]\tvalidation-auc:0.50457\ttrain-auc:0.67336\n",
      "[21]\tvalidation-auc:0.50462\ttrain-auc:0.67706\n",
      "[22]\tvalidation-auc:0.50467\ttrain-auc:0.68057\n",
      "[23]\tvalidation-auc:0.50390\ttrain-auc:0.68448\n",
      "[24]\tvalidation-auc:0.50295\ttrain-auc:0.68805\n",
      "[25]\tvalidation-auc:0.50301\ttrain-auc:0.69104\n",
      "[26]\tvalidation-auc:0.50183\ttrain-auc:0.69395\n",
      "[27]\tvalidation-auc:0.50186\ttrain-auc:0.69679\n",
      "[28]\tvalidation-auc:0.50201\ttrain-auc:0.69959\n",
      "[29]\tvalidation-auc:0.50168\ttrain-auc:0.70263\n",
      "[30]\tvalidation-auc:0.50114\ttrain-auc:0.70531\n",
      "[31]\tvalidation-auc:0.50171\ttrain-auc:0.70850\n",
      "[32]\tvalidation-auc:0.50034\ttrain-auc:0.71130\n",
      "[33]\tvalidation-auc:0.49992\ttrain-auc:0.71402\n",
      "[34]\tvalidation-auc:0.49865\ttrain-auc:0.71656\n",
      "[35]\tvalidation-auc:0.49920\ttrain-auc:0.71903\n",
      "[36]\tvalidation-auc:0.49856\ttrain-auc:0.72159\n",
      "[37]\tvalidation-auc:0.49902\ttrain-auc:0.72425\n",
      "[38]\tvalidation-auc:0.50005\ttrain-auc:0.72660\n",
      "[39]\tvalidation-auc:0.49943\ttrain-auc:0.72938\n",
      "[40]\tvalidation-auc:0.49908\ttrain-auc:0.73180\n",
      "[41]\tvalidation-auc:0.49897\ttrain-auc:0.73420\n",
      "[42]\tvalidation-auc:0.49937\ttrain-auc:0.73656\n",
      "[43]\tvalidation-auc:0.49953\ttrain-auc:0.73864\n",
      "[44]\tvalidation-auc:0.49981\ttrain-auc:0.74092\n",
      "[45]\tvalidation-auc:0.49934\ttrain-auc:0.74332\n",
      "[46]\tvalidation-auc:0.49932\ttrain-auc:0.74543\n",
      "[47]\tvalidation-auc:0.50002\ttrain-auc:0.74785\n",
      "[48]\tvalidation-auc:0.49933\ttrain-auc:0.75005\n",
      "[49]\tvalidation-auc:0.49960\ttrain-auc:0.75208\n",
      "[50]\tvalidation-auc:0.50003\ttrain-auc:0.75435\n",
      "[51]\tvalidation-auc:0.49980\ttrain-auc:0.75647\n",
      "[52]\tvalidation-auc:0.50016\ttrain-auc:0.75830\n",
      "[53]\tvalidation-auc:0.49982\ttrain-auc:0.76027\n",
      "[54]\tvalidation-auc:0.50010\ttrain-auc:0.76177\n",
      "[55]\tvalidation-auc:0.49987\ttrain-auc:0.76381\n",
      "[56]\tvalidation-auc:0.50008\ttrain-auc:0.76577\n",
      "[57]\tvalidation-auc:0.49947\ttrain-auc:0.76766\n",
      "[58]\tvalidation-auc:0.49936\ttrain-auc:0.76910\n",
      "[59]\tvalidation-auc:0.49976\ttrain-auc:0.77112\n",
      "[60]\tvalidation-auc:0.50000\ttrain-auc:0.77282\n",
      "[61]\tvalidation-auc:0.50077\ttrain-auc:0.77490\n",
      "[62]\tvalidation-auc:0.49943\ttrain-auc:0.77663\n",
      "[63]\tvalidation-auc:0.49961\ttrain-auc:0.77829\n",
      "[64]\tvalidation-auc:0.49978\ttrain-auc:0.77991\n",
      "[65]\tvalidation-auc:0.50003\ttrain-auc:0.78165\n",
      "[66]\tvalidation-auc:0.49925\ttrain-auc:0.78350\n",
      "[67]\tvalidation-auc:0.49955\ttrain-auc:0.78509\n",
      "[68]\tvalidation-auc:0.49954\ttrain-auc:0.78641\n",
      "[69]\tvalidation-auc:0.49938\ttrain-auc:0.78828\n",
      "[70]\tvalidation-auc:0.49896\ttrain-auc:0.79021\n",
      "[71]\tvalidation-auc:0.49878\ttrain-auc:0.79179\n",
      "[72]\tvalidation-auc:0.49848\ttrain-auc:0.79299\n",
      "[73]\tvalidation-auc:0.49778\ttrain-auc:0.79452\n",
      "[74]\tvalidation-auc:0.49721\ttrain-auc:0.79582\n",
      "[75]\tvalidation-auc:0.49704\ttrain-auc:0.79736\n",
      "[76]\tvalidation-auc:0.49758\ttrain-auc:0.79877\n",
      "[77]\tvalidation-auc:0.49738\ttrain-auc:0.80039\n",
      "[78]\tvalidation-auc:0.49735\ttrain-auc:0.80181\n",
      "[79]\tvalidation-auc:0.49774\ttrain-auc:0.80309\n",
      "[80]\tvalidation-auc:0.49793\ttrain-auc:0.80460\n",
      "[81]\tvalidation-auc:0.49770\ttrain-auc:0.80589\n",
      "[82]\tvalidation-auc:0.49833\ttrain-auc:0.80730\n",
      "[83]\tvalidation-auc:0.49824\ttrain-auc:0.80871\n",
      "[84]\tvalidation-auc:0.49903\ttrain-auc:0.81035\n",
      "[85]\tvalidation-auc:0.49915\ttrain-auc:0.81174\n",
      "[86]\tvalidation-auc:0.49952\ttrain-auc:0.81320\n",
      "[87]\tvalidation-auc:0.49958\ttrain-auc:0.81455\n",
      "[88]\tvalidation-auc:0.49955\ttrain-auc:0.81605\n",
      "[89]\tvalidation-auc:0.49957\ttrain-auc:0.81740\n",
      "[90]\tvalidation-auc:0.49966\ttrain-auc:0.81873\n",
      "[91]\tvalidation-auc:0.49958\ttrain-auc:0.82017\n",
      "[92]\tvalidation-auc:0.49955\ttrain-auc:0.82149\n",
      "[93]\tvalidation-auc:0.50003\ttrain-auc:0.82258\n",
      "[94]\tvalidation-auc:0.49968\ttrain-auc:0.82414\n",
      "[95]\tvalidation-auc:0.49976\ttrain-auc:0.82532\n",
      "[96]\tvalidation-auc:0.49993\ttrain-auc:0.82664\n",
      "[97]\tvalidation-auc:0.49997\ttrain-auc:0.82794\n",
      "[98]\tvalidation-auc:0.49965\ttrain-auc:0.82895\n",
      "[99]\tvalidation-auc:0.49961\ttrain-auc:0.83018\n",
      "CPU times: user 37 s, sys: 516 ms, total: 37.6 s\n",
      "Wall time: 7.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bst = xgb.train(params, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run XGBoost with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T21:03:57.443698Z",
     "start_time": "2018-11-06T21:03:57.438288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'silent': 1, 'tree_method': 'gpu_hist', 'n_gpus': 1, 'eval_metric': 'auc', 'objective': 'binary:logistic'}\n"
     ]
    }
   ],
   "source": [
    "# instantiate params\n",
    "params = {}\n",
    "\n",
    "# general params\n",
    "general_params = {'silent': 1}\n",
    "params.update(general_params)\n",
    "\n",
    "# booster params\n",
    "n_gpus = 1\n",
    "booster_params = {}\n",
    "\n",
    "if n_gpus != 0:\n",
    "    booster_params['tree_method'] = 'gpu_hist'\n",
    "    booster_params['n_gpus'] = n_gpus\n",
    "params.update(booster_params)\n",
    "\n",
    "# learning task params\n",
    "learning_task_params = {'eval_metric': 'auc', 'objective': 'binary:logistic'}\n",
    "params.update(learning_task_params)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:42:18] WARNING: /conda/conda-bld/xgboost_1591204529699/work/include/xgboost/generic_parameters.h:35: \n",
      "n_gpus: \n",
      "\tDeprecated. Single process multi-GPU training is no longer supported.\n",
      "\tPlease switch to distributed training with one process per GPU.\n",
      "\tThis can be done using Dask or Spark.  See documentation for details.\n",
      "[09:42:18] WARNING: /conda/conda-bld/xgboost_1591204529699/work/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation-auc:0.50718\ttrain-auc:0.54219\n",
      "[1]\tvalidation-auc:0.50541\ttrain-auc:0.55878\n",
      "[2]\tvalidation-auc:0.50782\ttrain-auc:0.56994\n",
      "[3]\tvalidation-auc:0.51270\ttrain-auc:0.58049\n",
      "[4]\tvalidation-auc:0.50758\ttrain-auc:0.58882\n",
      "[5]\tvalidation-auc:0.50772\ttrain-auc:0.59639\n",
      "[6]\tvalidation-auc:0.50897\ttrain-auc:0.60430\n",
      "[7]\tvalidation-auc:0.50962\ttrain-auc:0.61053\n",
      "[8]\tvalidation-auc:0.50935\ttrain-auc:0.61665\n",
      "[9]\tvalidation-auc:0.50636\ttrain-auc:0.62227\n",
      "[10]\tvalidation-auc:0.50519\ttrain-auc:0.62812\n",
      "[11]\tvalidation-auc:0.50463\ttrain-auc:0.63369\n",
      "[12]\tvalidation-auc:0.50427\ttrain-auc:0.63923\n",
      "[13]\tvalidation-auc:0.50484\ttrain-auc:0.64402\n",
      "[14]\tvalidation-auc:0.50718\ttrain-auc:0.64840\n",
      "[15]\tvalidation-auc:0.50809\ttrain-auc:0.65300\n",
      "[16]\tvalidation-auc:0.50677\ttrain-auc:0.65701\n",
      "[17]\tvalidation-auc:0.50706\ttrain-auc:0.66109\n",
      "[18]\tvalidation-auc:0.50516\ttrain-auc:0.66551\n",
      "[19]\tvalidation-auc:0.50649\ttrain-auc:0.66927\n",
      "[20]\tvalidation-auc:0.50457\ttrain-auc:0.67336\n",
      "[21]\tvalidation-auc:0.50462\ttrain-auc:0.67706\n",
      "[22]\tvalidation-auc:0.50467\ttrain-auc:0.68057\n",
      "[23]\tvalidation-auc:0.50390\ttrain-auc:0.68448\n",
      "[24]\tvalidation-auc:0.50295\ttrain-auc:0.68805\n",
      "[25]\tvalidation-auc:0.50301\ttrain-auc:0.69104\n",
      "[26]\tvalidation-auc:0.50183\ttrain-auc:0.69395\n",
      "[27]\tvalidation-auc:0.50186\ttrain-auc:0.69679\n",
      "[28]\tvalidation-auc:0.50201\ttrain-auc:0.69959\n",
      "[29]\tvalidation-auc:0.50168\ttrain-auc:0.70263\n",
      "[30]\tvalidation-auc:0.50114\ttrain-auc:0.70531\n",
      "[31]\tvalidation-auc:0.50171\ttrain-auc:0.70850\n",
      "[32]\tvalidation-auc:0.50034\ttrain-auc:0.71130\n",
      "[33]\tvalidation-auc:0.49992\ttrain-auc:0.71402\n",
      "[34]\tvalidation-auc:0.49865\ttrain-auc:0.71656\n",
      "[35]\tvalidation-auc:0.49920\ttrain-auc:0.71903\n",
      "[36]\tvalidation-auc:0.49856\ttrain-auc:0.72159\n",
      "[37]\tvalidation-auc:0.49902\ttrain-auc:0.72425\n",
      "[38]\tvalidation-auc:0.50005\ttrain-auc:0.72660\n",
      "[39]\tvalidation-auc:0.49943\ttrain-auc:0.72938\n",
      "[40]\tvalidation-auc:0.49908\ttrain-auc:0.73180\n",
      "[41]\tvalidation-auc:0.49897\ttrain-auc:0.73420\n",
      "[42]\tvalidation-auc:0.49937\ttrain-auc:0.73656\n",
      "[43]\tvalidation-auc:0.49953\ttrain-auc:0.73864\n",
      "[44]\tvalidation-auc:0.49981\ttrain-auc:0.74092\n",
      "[45]\tvalidation-auc:0.49934\ttrain-auc:0.74332\n",
      "[46]\tvalidation-auc:0.49932\ttrain-auc:0.74543\n",
      "[47]\tvalidation-auc:0.50002\ttrain-auc:0.74785\n",
      "[48]\tvalidation-auc:0.49933\ttrain-auc:0.75005\n",
      "[49]\tvalidation-auc:0.49960\ttrain-auc:0.75208\n",
      "[50]\tvalidation-auc:0.50003\ttrain-auc:0.75435\n",
      "[51]\tvalidation-auc:0.49980\ttrain-auc:0.75647\n",
      "[52]\tvalidation-auc:0.50016\ttrain-auc:0.75830\n",
      "[53]\tvalidation-auc:0.49982\ttrain-auc:0.76027\n",
      "[54]\tvalidation-auc:0.50010\ttrain-auc:0.76177\n",
      "[55]\tvalidation-auc:0.49987\ttrain-auc:0.76381\n",
      "[56]\tvalidation-auc:0.50008\ttrain-auc:0.76577\n",
      "[57]\tvalidation-auc:0.49947\ttrain-auc:0.76766\n",
      "[58]\tvalidation-auc:0.49936\ttrain-auc:0.76910\n",
      "[59]\tvalidation-auc:0.49976\ttrain-auc:0.77112\n",
      "[60]\tvalidation-auc:0.50000\ttrain-auc:0.77282\n",
      "[61]\tvalidation-auc:0.50077\ttrain-auc:0.77490\n",
      "[62]\tvalidation-auc:0.49943\ttrain-auc:0.77663\n",
      "[63]\tvalidation-auc:0.49961\ttrain-auc:0.77829\n",
      "[64]\tvalidation-auc:0.49978\ttrain-auc:0.77991\n",
      "[65]\tvalidation-auc:0.50003\ttrain-auc:0.78165\n",
      "[66]\tvalidation-auc:0.49925\ttrain-auc:0.78350\n",
      "[67]\tvalidation-auc:0.49955\ttrain-auc:0.78509\n",
      "[68]\tvalidation-auc:0.49954\ttrain-auc:0.78641\n",
      "[69]\tvalidation-auc:0.49938\ttrain-auc:0.78828\n",
      "[70]\tvalidation-auc:0.49896\ttrain-auc:0.79021\n",
      "[71]\tvalidation-auc:0.49878\ttrain-auc:0.79179\n",
      "[72]\tvalidation-auc:0.49848\ttrain-auc:0.79299\n",
      "[73]\tvalidation-auc:0.49778\ttrain-auc:0.79452\n",
      "[74]\tvalidation-auc:0.49721\ttrain-auc:0.79582\n",
      "[75]\tvalidation-auc:0.49704\ttrain-auc:0.79736\n",
      "[76]\tvalidation-auc:0.49758\ttrain-auc:0.79877\n",
      "[77]\tvalidation-auc:0.49738\ttrain-auc:0.80039\n",
      "[78]\tvalidation-auc:0.49735\ttrain-auc:0.80181\n",
      "[79]\tvalidation-auc:0.49774\ttrain-auc:0.80309\n",
      "[80]\tvalidation-auc:0.49793\ttrain-auc:0.80460\n",
      "[81]\tvalidation-auc:0.49770\ttrain-auc:0.80589\n",
      "[82]\tvalidation-auc:0.49833\ttrain-auc:0.80730\n",
      "[83]\tvalidation-auc:0.49824\ttrain-auc:0.80871\n",
      "[84]\tvalidation-auc:0.49903\ttrain-auc:0.81035\n",
      "[85]\tvalidation-auc:0.49915\ttrain-auc:0.81174\n",
      "[86]\tvalidation-auc:0.49952\ttrain-auc:0.81320\n",
      "[87]\tvalidation-auc:0.49958\ttrain-auc:0.81455\n",
      "[88]\tvalidation-auc:0.49955\ttrain-auc:0.81605\n",
      "[89]\tvalidation-auc:0.49957\ttrain-auc:0.81740\n",
      "[90]\tvalidation-auc:0.49966\ttrain-auc:0.81873\n",
      "[91]\tvalidation-auc:0.49958\ttrain-auc:0.82017\n",
      "[92]\tvalidation-auc:0.49955\ttrain-auc:0.82149\n",
      "[93]\tvalidation-auc:0.50003\ttrain-auc:0.82258\n",
      "[94]\tvalidation-auc:0.49968\ttrain-auc:0.82414\n",
      "[95]\tvalidation-auc:0.49976\ttrain-auc:0.82532\n",
      "[96]\tvalidation-auc:0.49993\ttrain-auc:0.82664\n",
      "[97]\tvalidation-auc:0.49997\ttrain-auc:0.82794\n",
      "[98]\tvalidation-auc:0.49965\ttrain-auc:0.82895\n",
      "[99]\tvalidation-auc:0.49961\ttrain-auc:0.83018\n",
      "CPU times: user 1.02 s, sys: 269 ms, total: 1.29 s\n",
      "Wall time: 1.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bst = xgb.train(params, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "To learn more about RAPIDS, be sure to check out: \n",
    "\n",
    "* [Open Source Website](http://rapids.ai)\n",
    "* [GitHub](https://github.com/rapidsai/)\n",
    "* [Press Release](https://nvidianews.nvidia.com/news/nvidia-introduces-rapids-open-source-gpu-acceleration-platform-for-large-scale-data-analytics-and-machine-learning)\n",
    "* [NVIDIA Blog](https://blogs.nvidia.com/blog/2018/10/10/rapids-data-science-open-source-community/)\n",
    "* [Developer Blog](https://devblogs.nvidia.com/gpu-accelerated-analytics-rapids/)\n",
    "* [NVIDIA Data Science Webpage](https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
